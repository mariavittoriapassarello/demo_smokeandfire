{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f78800c3-7a8b-45d8-b2c2-249b00fa757e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/opt/app-root/lib64/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/opt/app-root/lib64/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/opt/app-root/lib64/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/opt/app-root/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q ultralytics onnx onnxslim onnxruntime torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5ece48b-8e4a-4615-8a2d-35bf49655784",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import ultralytics\n",
    "except Exception as e:\n",
    "    print(f\"{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1445be2-e289-4396-9877-54a8da63f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ultralytics.YOLO(\"./runs/detect/train2/weights/last.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78c40d57-0a34-47fc-91ec-4eefe7f9e3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.205 ðŸš€ Python-3.12.9 torch-2.8.0+cu128 CPU (AMD EPYC 7R13 Processor)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/detect/train2/weights/last.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (5.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.18.0 opset 22...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.70...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 2.3s, saved as 'runs/detect/train2/weights/last.onnx' (10.1 MB)\n",
      "\n",
      "Export complete (3.4s)\n",
      "Results saved to \u001b[1m/opt/app-root/src/wb2/Real-Time-Smoke-Fire-Detection-YOLO11/notebook/runs/detect/train2/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=runs/detect/train2/weights/last.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=runs/detect/train2/weights/last.onnx imgsz=640 data=Fire-Smoke-Detection-Yolov11-2/data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "onnx_model = model.export(format=\"onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a89272f-b197-4571-8a7d-8cbc29877c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX Model:\n",
      " Input: images, shape: [1, 3, 640, 640]\n",
      " Output: output0, shape: [1, 6, 8400]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as rt\n",
    "\n",
    "onnx_ckpt = \"./runs/detect/train2/weights/last.onnx\"\n",
    "# load checkpoint from disk\n",
    "onnx_model = rt.InferenceSession(onnx_ckpt, providers=rt.get_available_providers())\n",
    "\n",
    "# get inputs and outputs of the onnx model\n",
    "onnx_input = onnx_model.get_inputs()[0]\n",
    "onnx_output = onnx_model.get_outputs()[0]\n",
    "input_name = onnx_input.name\n",
    "output_name = onnx_output.name\n",
    "\n",
    "print(f\"ONNX Model:\\n Input: {input_name}, shape: {onnx_input.shape}\\n Output: {output_name}, shape: {onnx_output.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0b9f8-633b-4850-9c59-3ad29610c088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
